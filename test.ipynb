{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# from utils import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0593, -0.5259, -0.4126, -1.2237, -1.0999],\n",
      "        [ 0.2725,  0.1745,  1.4604, -0.2560,  0.4010],\n",
      "        [ 0.3831,  0.0097,  1.1761, -0.1994,  2.6107]], requires_grad=True)\n",
      "tensor([[0.2939, 0.3446, 0.2175, 0.0216, 0.1223],\n",
      "        [0.0919, 0.1213, 0.1271, 0.4115, 0.2481],\n",
      "        [0.3606, 0.0967, 0.1421, 0.3822, 0.0183]])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "print(input)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2500, 0.0000, 0.1875],\n",
      "        [1.0000, 0.0000, 0.3750],\n",
      "        [1.7500, 0.0000, 0.5625]])\n",
      "[[0.25   0.     0.75  ]\n",
      " [0.4    0.     0.6   ]\n",
      " [0.4375 0.     0.5625]]\n",
      "tensor([ 4, 10, 16]) [[ 4.]\n",
      " [10.]\n",
      " [16.]]\n"
     ]
    }
   ],
   "source": [
    "cm1 = torch.tensor([[1,0,3],[4,0,6],[7,0,9]])\n",
    "cm2 = np.array([[1,0,3],[4,0,6],[7,0,9]])\n",
    "cs1 = cm1.sum(dim=1)\n",
    "cs1 = cs1.masked_fill_(cs1 == 0, 1e-10)\n",
    "cs2 = cm2.sum(axis=1, keepdims=True)\n",
    "cs2 = np.where(cs2 == 0, 1e-10, cs2)\n",
    "print(cm1/cs1)\n",
    "print(cm2/cs2)\n",
    "print(cs1, cs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 66992\n",
      "Number of validation samples: 25258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3243452/49864393.py:14: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  train_df = main_corpus_df[corpus_df[\"Split_Set\"] == \"Train\"]\n",
      "/tmp/ipykernel_3243452/49864393.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  val_df = main_corpus_df[corpus_df[\"Split_Set\"] == \"Development\"]\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "corpus = \"MSPPODCAST\"\n",
    "text_feature_extractor = 'roberta-large-UTT'\n",
    "audio_feature_extractor = 'whisper-large-v3-UTT'\n",
    "seed = 42\n",
    "batch = 16\n",
    "# Data Preprocessing\n",
    "corpus_path = config[corpus][\"PATH_TO_LABEL\"]\n",
    "corpus_df = pd.read_csv(corpus_path)\n",
    "corpus_df[\"FileName\"]= corpus_df[\"FileName\"].str.replace('.wav', '')\n",
    "# Remove non consensus labels\n",
    "main_corpus_df = corpus_df[~corpus_df[\"EmoClass\"].isin([\"X\", \"O\"])]\n",
    "# Create train/val splits\n",
    "train_df = main_corpus_df[corpus_df[\"Split_Set\"] == \"Train\"]\n",
    "val_df = main_corpus_df[corpus_df[\"Split_Set\"] == \"Development\"]\n",
    "# test_df = pd.read_csv(config[corpus][\"PATH_TO_TEST\"]) For evaluate.py\n",
    "text_feature = get_feature_dir(corpus,text_feature_extractor)\n",
    "audio_feature = get_feature_dir(corpus,audio_feature_extractor)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CustomDataset(train_df, text_feature, audio_feature, seed=seed)\n",
    "valid_dataset = CustomDataset(val_df, text_feature, audio_feature, seed=seed)\n",
    "print(f\"Number of training samples: {train_dataset.total_samples}\")\n",
    "print(f\"Number of validation samples: {valid_dataset.total_samples}\")\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch, num_workers=16)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexEmotion(index_list):\n",
    "    category_list = []\n",
    "    emotions = [\"Angry\", \"Sad\", \"Happy\", \"Surprise\", \"Fear\", \"Disgust\", \"Contempt\", \"Neutral\"]\n",
    "    for index in index_list:\n",
    "        category_list.append(emotions[index])\n",
    "    return category_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check distribution of emotion categories\n",
    "total_categories = []\n",
    "for batch_idx, (data, label) in enumerate(train_loader):\n",
    "    category = label[\"category\"]\n",
    "    total_categories.extend(torch.argmax(category, dim=1).tolist())\n",
    "category_list = indexEmotion(total_categories)\n",
    "\n",
    "# Create distribution plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "category_counts = pd.Series(category_list).value_counts()\n",
    "sns.barplot(x=category_counts.index, y=category_counts.values)\n",
    "plt.title('Distribution of Emotion Categories')\n",
    "plt.xlabel('Emotion')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class weights for CrossEntropyLoss:\n",
      "Angry: 1.247\n",
      "Sad: 1.308\n",
      "Happy: 0.503\n",
      "Surprise: 2.798\n",
      "Fear: 7.383\n",
      "Disgust: 5.900\n",
      "Contempt: 3.324\n",
      "Neutral: 0.287\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights inversely proportional to class frequencies\n",
    "total_samples = len(category_list)\n",
    "class_weights = []\n",
    "emotions = [\"Angry\", \"Sad\", \"Happy\", \"Surprise\", \"Fear\", \"Disgust\", \"Contempt\", \"Neutral\"]\n",
    "for emotion in emotions:\n",
    "    count = category_counts.get(emotion, 0)\n",
    "    if count == 0:\n",
    "        weight = 1.0  # Handle case where class has no samples\n",
    "    else:\n",
    "        weight = total_samples / (len(emotions) * count)\n",
    "    class_weights.append(weight)\n",
    "\n",
    "# Convert to tensor for CrossEntropyLoss\n",
    "class_weights = torch.FloatTensor(class_weights).cuda()\n",
    "print(\"\\nClass weights for CrossEntropyLoss:\")\n",
    "for emotion, weight in zip(emotions, class_weights):\n",
    "    print(f\"{emotion}: {weight:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.AdaptiveAvgPool1d(5)\n",
    "input = torch.randint(1, 64, (8,))\n",
    "input = input.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21., 58., 39., 51., 33., 56., 13., 28.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(42.2500), tensor(45.2500), tensor(44.7500), tensor(38.2500)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = []\n",
    "for i in range(0,4):\n",
    "    test.append(input[i:i+4].mean())\n",
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[39.5000, 49.3333, 42.0000, 34.0000, 20.5000]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = m(input.unsqueeze(0))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[42.2500, 45.2500, 44.7500, 38.2500, 32.5000]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = nn.AvgPool1d(4, stride=1)\n",
    "output2 = m2(input.unsqueeze(0))\n",
    "output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 512])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(32,512)\n",
    "x = x.unsqueeze(1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8//3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
