[base_config]
corpus = "TOTAL"
origin_upstream_url = "facebook/wav2vec2-base"
upstream_model = "wav2vec2-base"
epoch = 15
batch_size = 16
learning_rate = 5e-5
dropout = 0.2
patience = 5
verbose = true
seed = 42
tags = ["Small set","Gender Tune","Dual Head"]
hidden_dim = 64
finetune_layers = 3
classifier_output_dim = 6
num_layers = 3
use_feature = false
use_gender = true
ckpt_name = "None"

[[experiments]]
name = "Testing"
model_type = "UpstreamGender"
config = "base_config"
config_update = { ckpt_name = "CombineCorpus_Gender", tags = ["hello world"] }

[[experiments]]
name = "Testing"
model_type = "UpstreamFinetune"
config = "base_config"
config_update = { ckpt_name = "CombineCorpus_ORG", tags = ["heee"] }


# Drop out test

# For remote running
# [[experiments]]
# name = "Wav2vec2 finetune (2 layers)"
# model_type = "UpstreamFinetune"
# config = "base_config"
# config_update = { finetune_layers = 2 }

# [[experiments]]
# name = "Wav2vec2 finetune (3 layers)"
# model_type = "UpstreamFinetune"
# config = "base_config"
# config_update = { finetune_layers = 3 }

# [[experiments]]
# name = "Wav2vec2 finetune (4 layers)"
# model_type = "UpstreamFinetune"
# config = "base_config"
# config_update = { finetune_layers = 4 }

# [[experiments]]
# # LSTM with multi-head attention
# name = "LSTM with Multi-Head Attention (4 heads)"
# model_type = "lstm_multihead"
# config = "base_config"
# config_update = { num_heads = 4 }

# [[experiments]]
# # Variations of hidden dimensions
# name = "LSTM with Attention (32 Hidden Units)"
# model_type = "lstm_attention"
# config = "base_config"
# config_update = { hidden_dim = 32 }
